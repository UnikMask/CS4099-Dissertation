#+TITLE: Determinization and Minimization of Non-Deterministic Finite State Automatas - A Distributed Approach
#+AUTHOR: A. Guerville



#+LATEX_HEADER: \usepackage{fancyhdr}
#+LATEX_HEADER: \usepackage[a4paper, total={6in, 8in}]{geometry}
#+LATEX_HEADER: \usepackage{fontspec}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usepackage{algorithm}
#+LATEX_HEADER: \usepackage{algpseudocode}
#+LATEX_HEADER: \pagestyle{fancy}
#+LATEX_HEADER: \fancyhf{}
#+LATEX_HEADER: \lhead{Determinization and Minimization of Non-Deterministic NFAs - A Distributed Approach}
#+LATEX_HEADER: \fancyfoot[RO, LE] {Page \thepage}


* Introduction
Finite State Automata are one of the most fundamental concepts in Computer Science. Their uses range everywhere from parsing
to mathematical theory. Finite State Automata exist in two kinds: Deterministic Finite Automata (DFAs) and Non-Deterministic
Finite Automata (NFAs). It is well-known that both structures describe the same set of languages (regular languages), but
it is in general significantly easier to work with DFAs than NFAs. Some problems are first transcribed into NFAs, therefore
the determinization of a DFA into a NFA, and it's minimization, are critical steps into the understanding of those problems.

Here, a set of determinization and minimization algorithms, ranging from single-threaded to distributed, is described and
implemented to solve that task, and tested on a problem class about the determinization of NFAs: Transportation Graphs AKA
Token Passing Networks.

* Related Works
Single-threaded NFA determinization and minization algorithms have existed since the 1950s. DFA determinization's /Rabin-Scott superset construction/ algorithm is a well-known determinization algorithm which has existed for a long time. However, DFA
minimization is younger, and the most well-known minimization algorithm today is Hopcroft's minimization algorithm.

Parallel NFA determinization algorithms have begun being researched round the 1990s. For example, \cite{508056} ran
a parallel NFA determinization and minimization algorithm on a supercomputer, using a message passing model instead of
shared memory.

In 2007, \cite{DBLP_journal} implements a disk-based distributed algorithm for large NFAs. A disk-based approach avoids the
RAM memory space issues from previous implementations.

Later, \cite{Slavici2012AnEP} proposes a general programming model to migrate RAM-based legacy algorithms into parallel
disks - and applies the model to NFA determinization and minimization.

In 2020, \cite{Ba2020OnTD} uses Bulk Synchronous Parallel abstract computer model to implement a more
performant distributed NFA determinization and minization algorithm.

Finally, \cite{A2022ACS} compares both the MapReduce and BSP-based NFA determinization and minimization algorithm, finding
that the BSP/Pregel based solution outperforms the MapReduce solution.


* Token Passing Networks
A token passing network is a directed graph \(G = (V, E)\) such that:
+ \(V\): Vertices/nodes,
+ \(E \in (V \times label \times V)\): edges - an edge connects a vertex to another, and may contain a label.
+ There exists a single input node \(I\) in \(V\) such that there is not ingoing edges to it -
  \[!\exists I \in V. \nexists v_{2}. \exists v_{1}. \exists e = (v_{1}, v_{2}) \in E. v_{2} = I\]
+ There exists a single output node \(O\) in \(V\) such that there is no ougoing edges from it -
  \[!\exists O \in V. \nexists v_{1}. \exists v_{2}. \exists e = (v_{1}, v_{2}) \in E. v_{1} = O\]

Token Passing Networks, originally called Transportation Graphs by \cite{ATKINSON1997103}, were originally studied
by \cite{ATKINSON1997103} in order to think about what kind of packet permutations might arise from packet delay in networks.

Design patterns in transportation graphs can introduce properties for a transition graph, as well. For example, figure
\ref{fig:infstack} shows the design of an infinite stack data structure, where \(S\) represents an infinite number
of nodes connected as shows figure \ref{fig:stackinsides}.

#+CAPTION: Example of a stack TPN
#+ATTR_LATEX: :float nil
\begin{figure}
\centering
\begin{tikzpicture}[main/.style = {draw, circle}]
    \node[main] (1) {$I$};
    \node[main] (2) [right of=1] {$S$};
    \node[main] (3) [right of=2] {$O$};
    \draw[->] (1) -- (2);
    \draw[->] (2) -- (3);
\end{tikzpicture}
\label{fig:infstack}
\end{figure}


#+CAPTION: Inner Workings of a size 3 TPN stack
#+ATTR_LATEX: :float nil
\begin{figure}
\centering
\begin{tikzpicture}[main/.style = {draw, circle}]
    \node[main] (1) {$S_{1}$};
    \node[main] (2) [below of=1] {$S_{2}$};
    \node[main] (3) [below of=2] {$S_{3}$};
    \draw[->] (1) -- (2);
    \draw[->] (2) -- (1);
    \draw[->] (2) -- (3);
    \draw[->] (3) -- (2);
\end{tikzpicture}
\label{fig:stackinsides}
\end{figure}

Transportation graphs are used as such:
+ Each node can store one "token",
+ "Tokens" can be fetched from the input node \(I\) to the next node,
+ "Tokens" must be transported to the output node \(O\),
+ After all "tokens" from the input stream are consumed, there should be no tokens remaining in the graph.

Tokens are kept in track by keeping the order at which the tokens arrived in. Therefore, it is possible to study the
possible order at which the tokens arrive at with a given transportation graph.


** Permutation Classes and 3-1-2 avoidance
As described previously, it is possible to describe what possible orders the tokens may arrive at from a token passing
network. Such area of study comes from a property of stacks, which is what kinds of permutations are Stack Sortable.

For example, \cite{Waton2007onPC} describes properties of stacks in regards to what permutations they accept.

#+CAPTION: Graphical Example of a stack
#+ATTR_LATEX: :float nil
\begin{figure}
\centering
\begin{tikzpicture} [main/.style = {draw}]
    \draw (0, 0) -- (1, 0) -- (1, -2) -- (2, -2) -- (2, 0) -- (3, 0);
    \node (input) at (2.5, 0.25) {Input};
    \node (output) at (0.5, 0.25) {Output};
\end{tikzpicture}
\label{fig:graphstack}
\end{figure}

Figure \ref{fig:graphstack} shows a graphical representation of a stack, with an input stream on the right, containing
a stream of tokens, and an output stream on the left, which accepts tokens. On one hand, figure \ref{fig:graphperms}
describes a permutation which is accepted by a stack.


#+CAPTION: Successful Stack Permutation
#+ATTR_LATEX: :float nil
\begin{figure}
\centering
\begin{tikzpicture} [main/.style = {draw}]
    \draw (-0.25, 0) -- (0.5, 0) -- (0.5, -1) -- (1, -1) -- (1, 0) -- (1.75, 0);
    \node (input) at (1.5, 0.25) {1 2 3};
    \node (output) at (0, 0.25) {};
\end{tikzpicture}
\begin{tikzpicture} [main/.style = {draw}]
    \draw (-0.25, 0) -- (0.5, 0) -- (0.5, -1) -- (1, -1) -- (1, 0) -- (1.75, 0);
    \node (input) at (1.5, 0.25) {2 3};
    \node (s1) at (0.75, -0.75) {1};
    \node (output) at (0, 0.25) {};
\end{tikzpicture}
\begin{tikzpicture} [main/.style = {draw}]
    \draw (-0.25, 0) -- (0.5, 0) -- (0.5, -1) -- (1, -1) -- (1, 0) -- (1.75, 0);
    \node (input) at (1.5, 0.25) {3};
    \node (s1) at (0.75, -0.75) {1};
    \node (s2) at (0.75, -0.25) {2};
    \node (output) at (0, 0.25) {};
\end{tikzpicture}
\begin{tikzpicture} [main/.style = {draw}]
    \draw (-0.25, 0) -- (0.5, 0) -- (0.5, -1) -- (1, -1) -- (1, 0) -- (1.75, 0);
    \node (input) at (1.5, 0.25) {};
    \node (s1) at (0.75, -0.75) {1};
    \node (s2) at (0.75, -0.25) {2};
    \node (output) at (0, 0.25) {3};
\end{tikzpicture}
\begin{tikzpicture} [main/.style = {draw}]
    \draw (-0.25, 0) -- (0.5, 0) -- (0.5, -1) -- (1, -1) -- (1, 0) -- (1.75, 0);
    \node (input) at (1.5, 0.25) {};
    \node (s1) at (0.75, -0.75) {1};
    \node (output) at (0, 0.25) {3 2};
\end{tikzpicture}
\begin{tikzpicture} [main/.style = {draw}]
    \draw (-0.25, 0) -- (0.5, 0) -- (0.5, -1) -- (1, -1) -- (1, 0) -- (1.75, 0);
    \node (input) at (1.25, 0.25) {};
    \node (output) at (0, 0.25) {3 2 1};
\end{tikzpicture}
\label{fig:graphperms}
\end{figure}

On the other hand, \ref{fig:312avoidance} presents a permutation which is is not accepted by a stack. As the figure shows,
it is possible to pass the 3rd token to the output first, but then it is impossible to pass the first token, as token 2 is
at the front. This class of pattern is called 3-1-2 avoidance/ 2-3-1 avoidance.

The 3-1-2 pattern or 2-3-1 pattern depends
on whether the stack tries reorder a sequence of tokens (2-3-1 exclusion), or it tries to permute an ordered sequence.
It is therefore said that 2-3-1 is the inverse pattern of 3-1-2.

#+CAPTION: 3-1-2 Avoidance in a Stack
#+ATTR_LATEX: :float nil
\begin{figure}
\centering
\begin{tikzpicture} [main/.style = {draw}]
    \draw (0, 0) -- (1, 0) -- (1, -2) -- (2, -2) -- (2, 0) -- (3, 0);
    \node (input) at (2.5, 0.25) {1 2 3};
    \node (output) at (0.5, 0.25) {};
\end{tikzpicture}
\begin{tikzpicture} [main/.style = {draw}]
    \draw (0, 0) -- (1, 0) -- (1, -2) -- (2, -2) -- (2, 0) -- (3, 0);
    \node (input) at (2.5, 0.25) {2 3};
    \node (s1) at (1.5, -1.75) {1};
    \node (output) at (0.5, 0.25) {};
\end{tikzpicture}
\begin{tikzpicture} [main/.style = {draw}]
    \draw (0, 0) -- (1, 0) -- (1, -2) -- (2, -2) -- (2, 0) -- (3, 0);
    \node (input) at (2.5, 0.25) {3};
    \node (s1) at (1.5, -1.75) {1};
    \node (s2) at (1.5, -1.25) {2};
    \node (output) at (0.5, 0.25) {};
\end{tikzpicture}
\begin{tikzpicture} [main/.style = {draw}]
    \draw (0, 0) -- (1, 0) -- (1, -2) -- (2, -2) -- (2, 0) -- (3, 0);
    \node (input) at (2.5, 0.25) {};
    \node (s1) at (1.5, -1.75) {1};
    \node (s2) at (1.5, -1.25) {2};
    \node (output) at (0.5, 0.25) {3};
\end{tikzpicture}
\label{fig:312avoidance}
\end{figure}

Thus, the stack model can be modelled with transportation graphs using a stack of nodes, hence the study of accepted
permutations for a transportation graph.

** Conversion into NFA
A property of token passing networks, is that they can be converted into NFAs, in which the alphabet represents the
rank encoding of a token, and a state is represented by the order of a token on the initial ordered input stream.

The following definition from \cite{Waton2007onPC} defines a /rank encoding/ -
\begin{quote}
The $rank$ $encoding$ of a permutation is generated by replacing each element by its value relative to those
elements which come after it.
\end{quote}

From the rank encoding it is easy to describe the language of all accepted permutations of a transportation graph, hence
the wish to convert transportation graphs into NFAs, and to determinize and minimize them.

* Testing & Benchmarking
** Behaviour Testing
#+TODO: Unit testing case-by-case
** Benchmarking
#+TODO: GAP-generated NFAs
#+TODO: Self-generated NFAS

* Sequential Approach
** Approach to Determinization
First of all, NFA determinization is a well-known process, and efficient algorithms for it have existed for a long time.
The most widely-used algorithm for determinization is the superset construction algorithm, which explores the NFA from node
to node, keeping track of the sets of states visited in a map, until we've explored all reachable nodes.

The major advantage of this algorithm over any other is that it only explores reachable states in the NFA, and produces only
reachable states in the resulting DFA. The consequences are two-fold:
+ 1. The amount of exploration involved is severely decreased, depending on the NFA that is determinized,
+ 2. There is no need to remove unreachable states from the resulting DFA after determinization and before minimization.

The algorithm possesses shared memory in form of \(M\), the structure that maps a kept set of states to the number that it
is assigned on the final DFA, because the algorithm needs to check if a state has already been found after producing it.

#+CAPTION: Rabin Scott's Superset Construction Algorithm
\begin{algorithm}
\begin{algorithmic}[1]
\Procedure{SupersetConstruction}{\(M = (S, \Sigma, \delta, S_{0}, T)\)}
\State \(M\) \gets [(\(S_{0}, 0\))]
\State \(T^{'}\) \gets []
\If{\(\exists s \in S_{0}. s \in T\)}
    \State \(T^{'}\) \gets [\(S_{0}\)]
\EndIf
\State \(F\) \gets [\(S_{0}\)]
\While{\(F \neq \emptyset\)}
    \State \(S_{next}\) \gets pop from \(F\)
    \ForAll{\(a \in \Sigma\)}
        \State \(S^{'}\) \gets {}
        \ForAll{\(s \in S_{next}\)}
            \State Add \(s\) and all \epsilon transitions from \(s\)to \(S^{'}\)
        \EndFor
        \If{\(S_{next} \notin M\)}
            \State \(M\) \gets [\(M\), \((S^{'}, \left| M \right|)\)]
            \If{\(\exists s \in T. s \in S^{'}\)}
                \State \(T^{'}\) \gets [\(T^{'}, S^{'}\)]
            \EndIf
            \State \(F\) \gets [\(F\), \(S^{'}\)]
        \EndIf
        \State \(\delta^{'}\) \gets [\(\delta^{'}\), (\(S_{next}\), \(a\), \(S^{'}\))]
    \EndFor
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

Complexity-wise, the worst-case time complexity of the superset construction is \(O(2^{n})\), where \(n\) is the number of states in the original NFA.
Such worst-case is unavoidable as the size of the superset of states in the NFA \(\left| \mathds{S}(S) \right| = 2^{\left| S \right|}\), where \(S\) is the set of states in the original NFA.
However, this treshold is generally never reached, hence the purpose of the superset construction algorithm.

** Approah to Minimization
While NFA determinization has been a well-known subject for a long time, DFA minimization on the other hand has less well-known algorithms. Out of all the minimization algorithms nowadays, 2 stand out as better
algorithms than the rest. Those are Hopcroft's algorithm and Brzozowski's minimization algorithm.

*** Hopcroft's Algorithm

Hopcroft's algorithm is the first, and probably the most well-known DFA minimization algorithm. It is based on Hopcroft-Karp's bipartite graph algorithm, which calculates the maximum cardinality matching for it.

Hopcrof't algorithm separates the states of the DFA into a set of 2 partitions - accept states and non-accept states. Then, until the frontier is empty, it explores if reverse transitions from states to other
overlap with partitions in the set of partitions. If it is the case, then it means the partition has to be divided further. The algorithm is repeated until all states in each partition share the same properties regarding
transitions, which means that the resulting DFA holds the same language than the original one, but at it's minimal size.

#+CAPTION: Hopcroft's Algorithm
\begin{algorithm}
\begin{algorithmic}[1]
\Procedure{HopcroftAlgo}{\(M = (S, \Sigma, \delta, s_{0}, T)\)}
    \State \(P\) \gets \([T, S \backslash T]\)
    \State \(Q\) \gets \([T, S \backslash T]\)
    \While{\( \left| Q \right| \neq 0\)}
        \State \(P_{next}\) \gets pop \(Q\)
        \ForAll{a \in \(\Sigma\), V \in \(P\)}
            \If{\(\delta^{-1}(P_{next}) \cap V \neq \emptyset \wedge V \backslash \delta^{-1}(P_{next}) \neq \emptyset\)}
                \State remove \(V\) from \(P\)
                \State push \(\delta^{-1}(P_{next}) \wedge V\) into \(P\)
                \State push \(V \backslash \delta^{-1}(P_{next})\) into \(P\)
                \If{\(V \in Q\)}
                    \State replace \([V]\) in \(Q\) with \([V \backslash \delta^{-1}(P_{next}), \delta^{-1}(P_{next}) \wedge V]\)
                \Else
                    \State add \(V \backslash \delta^{-1}(P_{next})\) and \(\delta^{-1}(P_{next}) \wedge V\) to \(Q\)
                \EndIf
            \EndIf
        \EndFor
    \EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}
#+TODO: Hopcroft Algo complexity and ramifications
*** Brzozowski's Algorithm
#+TODO: Brzozowski's workings
#+TODO: nfdeterminize support
** Benchmarking
*** GAP-generation vs self-generation
#+TODO: Show benchmark, show why difference occurs
*** Pitfalls
#+TODO: epsilon transitions

* Multithreaded Approach
** Towards a Multithreaded Approach
#+TODO: Pitfalls of sequential approach
#+TODO: Issues of shared memory in determinization and minimization
** New Algorithms
*** Determinization
#+TODO: Pseudocode shared memory superset construction
*** Minimization
#+TODO: Pseudocode shared memory minimization algo
** Benchmarking
#+TODO: Results against sequential approach



\bibliographystyle{ieeetr}
\bibliography{dissertation}
